{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **calt Demo Notebook**\n",
    "\n",
    "This notebook shows a minimal end‑to‑end workflow for the **calt** library:\n",
    "\n",
    "1. **Install and import** the library  \n",
    "2. **Generate** a dataset of *polynomial‑sum* examples  \n",
    "3. **Configure** the tokenizer and model  \n",
    "4. **Train** the Transformer  \n",
    "5. **Visualize** training result  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on Google Colab: \n",
    "- Change the runtime type to GPU (e.g., T4 GPU) from the Runtime tab -> Change runtime type -> GPU\n",
    "- The `Sympy` backend to simplify the installation dependencies. For extensive usage, we recommend using the `SageMath` backend, which for example allows parallel sample generations.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1  – Installation & Imports  \n",
    "Run the next cell to ensure **calt** and its dependencies are installed, then import the required Python packages.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install calt-x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ara_shun/workspace/calt/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7b2b2414dab0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "import random\n",
    "from sympy import GF, ZZ\n",
    "from sympy.polys.rings import ring, PolyElement\n",
    "from transformers import BartConfig, BartForConditionalGeneration as Transformer\n",
    "from transformers import TrainingArguments\n",
    "from calt import (\n",
    "    PolynomialTrainer,\n",
    "    data_loader,\n",
    ")\n",
    "from calt.generator.sympy import (\n",
    "    PolynomialSampler,\n",
    "    DatasetGenerator,\n",
    "    DatasetWriter,\n",
    ")\n",
    "from calt.data_loader.utils import (\n",
    "    load_eval_results,\n",
    "    parse_poly,\n",
    "    display_with_diff\n",
    ")\n",
    "import torch, random, numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2  – Dataset Generation *(Polynomial Addition)*  \n",
    "This cell uses `calt.generator` utilities to create a synthetic dataset of polynomial‑addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumProblemGenerator:\n",
    "    \"\"\"\n",
    "    Problem generator for polynomial sum problems.\n",
    "\n",
    "    This generator creates problems in which the input is a list of polynomials F = [f_1, f_2, ..., f_n],\n",
    "    and the output is a single polynomial g = f_1 + f_2 + ... + f_n.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, sampler: PolynomialSampler, max_polynomials: int, min_polynomials: int\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize polynomial sum generator.\n",
    "\n",
    "        Args:\n",
    "            sampler: Polynomial sampler\n",
    "            max_polynomials: Maximum number of polynomials in F\n",
    "            min_polynomials: Minimum number of polynomials in F\n",
    "        \"\"\"\n",
    "        self.sampler = sampler\n",
    "        self.max_polynomials = max_polynomials\n",
    "        self.min_polynomials = min_polynomials\n",
    "\n",
    "    def __call__(self, seed: int) -> Tuple[List[PolyElement], PolyElement]:\n",
    "        \"\"\"\n",
    "        Generate a single sample.\n",
    "\n",
    "        Each sample consists of:\n",
    "        - Input polynomial system F\n",
    "        - Output polynomial g (sum of F)\n",
    "\n",
    "        Args:\n",
    "            seed: Seed for random number generator\n",
    "        \"\"\"\n",
    "        random.seed(seed)\n",
    "\n",
    "        # Choose number of polynomials for this sample\n",
    "        num_polys = random.randint(self.min_polynomials, self.max_polynomials)\n",
    "\n",
    "        # Generate input polynomials using sampler\n",
    "        F = self.sampler.sample(num_samples=num_polys)\n",
    "\n",
    "        # Generate output polynomial g (sum of F)\n",
    "        g = sum(F)\n",
    "\n",
    "        return F, g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 4049 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 4999 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 6049 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 7199 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 8449 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 9799 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 10000 out of 10000 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "save_dir = \".\"\n",
    "\n",
    "# set up polynomial ring\n",
    "R, *gens = ring(\"x0,x1\", GF(7), order=\"grevlex\")\n",
    "# Initialize polynomial sampler\n",
    "sampler = PolynomialSampler(\n",
    "    ring=R,\n",
    "    max_num_terms=2,\n",
    "    max_degree=2,\n",
    "    min_degree=1,\n",
    "    degree_sampling=\"uniform\",  # \"uniform\" or \"fixed\"\n",
    "    term_sampling=\"uniform\",  # \"uniform\" or \"fixed\"\n",
    "    max_coeff=None,  # Used for RR and ZZ\n",
    "    num_bound=None,  # Used for QQ\n",
    "    strictly_conditioned=False,\n",
    "    nonzero_instance=True,\n",
    ")\n",
    "# Initialize problem generator\n",
    "problem_generator = SumProblemGenerator(\n",
    "    sampler=sampler,\n",
    "    max_polynomials=2,\n",
    "    min_polynomials=2,\n",
    ")\n",
    "# Initialize dataset generator\n",
    "dataset_generator = DatasetGenerator(\n",
    "    backend=\"multiprocessing\",\n",
    "    n_jobs=1,  # warning: the current version with Sympy backend only supports n_jobs=1.\n",
    "    verbose=True,\n",
    "    root_seed=100,\n",
    ")\n",
    "# Generate training set\n",
    "train_samples, _ = dataset_generator.run(\n",
    "    train=True,\n",
    "    num_samples=10000,\n",
    "    problem_generator=problem_generator,\n",
    ")\n",
    "# Generate test set\n",
    "test_samples, _ = dataset_generator.run(\n",
    "    train=False,\n",
    "    num_samples=1000,\n",
    "    problem_generator=problem_generator,\n",
    ")\n",
    "# Initialize writer\n",
    "dataset_writer = DatasetWriter(save_dir)\n",
    "# Save datasets\n",
    "dataset_writer.save_dataset(train_samples, tag=\"train\")\n",
    "dataset_writer.save_dataset(test_samples, tag=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3  – Model Configuration  \n",
    "Here we instantiate the tokenizer, define the Transformer architecture, and prepare the training pipeline.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to any dataset you like; here we assume the toy Sum dataset from the data‑generation notebook.\n",
    "TRAIN_PATH = \"train_raw.txt\"\n",
    "TEST_PATH = \"test_raw.txt\"\n",
    "dataset, tokenizer, data_collator = data_loader(\n",
    "    train_dataset_path=TRAIN_PATH,\n",
    "    test_dataset_path=TEST_PATH,\n",
    "    field=\"GF7\",\n",
    "    num_variables=2,\n",
    "    max_degree=10,  # Should cover the range of generated samples\n",
    "    max_coeff=7,   # Should cover the range of generated samples\n",
    "    max_length=256,\n",
    ")\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal architecture.\n",
    "model_cfg = BartConfig(\n",
    "    d_model=256,       # 'width' of the model\n",
    "    vocab_size=len(tokenizer.vocab),\n",
    "    encoder_layers=2,  # 'depth' of encoder network\n",
    "    decoder_layers=2,  # 'depth' of decoder network\n",
    "    max_position_embeddings=256,  # max length of input/output\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    decoder_start_token_id=tokenizer.bos_token_id,\n",
    "    max_length=256,  # max length of input/output\n",
    ")\n",
    "model = Transformer(config=model_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4  – Training Hyper‑parameters  \n",
    "Learning‑rate schedule, batch size, number of epochs, and other trainer options are declared in this cell.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"results/\",\n",
    "    num_train_epochs=20,\n",
    "    logging_steps=50,\n",
    "    per_device_train_batch_size=int(128),\n",
    "    per_device_eval_batch_size=int(128),\n",
    "    save_strategy=\"no\",  # skip checkpoints for the quick demo\n",
    "    seed=SEED,\n",
    "    remove_unused_columns=False,\n",
    "    label_names=[\"labels\"],\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5  – Model Training  \n",
    "Launch the training loop. Progress is typically logged to the console (and optionally to Weights & Biases).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1580' max='1580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1580/1580 00:34, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.066300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.236700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.999900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.794300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.651200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.559400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.509600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.460200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.413200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.386500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.361000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.346500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.335300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.312700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.295900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.279300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.265700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.255500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.249800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.244200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.239400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.235600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.230900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.217600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.219400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.218700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.214800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.214800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ara_shun/workspace/calt/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3465: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 256}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate on test set: 53.7 %\n"
     ]
    }
   ],
   "source": [
    "trainer = PolynomialTrainer(\n",
    "    args=args,\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# train\n",
    "results = trainer.train()\n",
    "trainer.save_model()\n",
    "metrics = results.metrics\n",
    "\n",
    "# eval\n",
    "eval_metrics = trainer.evaluate()\n",
    "metrics.update(eval_metrics)\n",
    "success_rate = trainer.generate_evaluation(max_length=128)\n",
    "metrics[\"success_rate\"] = success_rate\n",
    "\n",
    "# save metrics\n",
    "trainer.save_metrics(\"all\", metrics)\n",
    "\n",
    "print(f'success rate on test set: {100*metrics[\"success_rate\"]:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6  – Visualizing Training Results  \n",
    "Finally, we visualize the differences between the mispredicted samples and their correct counterparts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      " Success cases \n",
      "-------------------------\n",
      "===== sample id: 1 =====\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{aligned}\n",
       "        \\text{Ground truth\\,:}\\; & {}6 x + y + 1\\\\\n",
       "        \\text{Prediction\\,:}\\;   & {}6\\, x +y +1\n",
       "        \\end{aligned}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== sample id: 2 =====\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{aligned}\n",
       "        \\text{Ground truth\\,:}\\; & {}3 x^{2} + 5 x + 6\\\\\n",
       "        \\text{Prediction\\,:}\\;   & {}3\\, x^{2} +5\\, x +6\n",
       "        \\end{aligned}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== sample id: 5 =====\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{aligned}\n",
       "        \\text{Ground truth\\,:}\\; & {}2 x^{2} + 6 y^{2}\\\\\n",
       "        \\text{Prediction\\,:}\\;   & {}2\\, x^{2} +6\\, y^{2}\n",
       "        \\end{aligned}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== sample id: 6 =====\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{aligned}\n",
       "        \\text{Ground truth\\,:}\\; & {}3 x^{2} + 4 y\\\\\n",
       "        \\text{Prediction\\,:}\\;   & {}3\\, x^{2} +4\\, y\n",
       "        \\end{aligned}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== sample id: 7 =====\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{aligned}\n",
       "        \\text{Ground truth\\,:}\\; & {}x^{2} + 5 x + 3 y + 6\\\\\n",
       "        \\text{Prediction\\,:}\\;   & {}x^{2} +5\\, x +3\\, y +6\n",
       "        \\end{aligned}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------\n",
      " Failure cases \n",
      "-------------------------\n",
      "===== sample id: 3 =====\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{aligned}\n",
       "        \\text{Ground truth\\,:}\\; & {}3 x^{2} + 2 x y + x + 4 y^{2}\\\\\n",
       "        \\text{Prediction\\,:}\\;   & {}3\\, x^{2} +2\\, x\\, y +\\cancel{4}\\, x +4\\, y^{2}\n",
       "        \\end{aligned}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== sample id: 4 =====\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{aligned}\n",
       "        \\text{Ground truth\\,:}\\; & {}0\\\\\n",
       "        \\text{Prediction\\,:}\\;   & {}\\cancel{y}\n",
       "        \\end{aligned}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== sample id: 8 =====\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{aligned}\n",
       "        \\text{Ground truth\\,:}\\; & {}2 y + 6\\\\\n",
       "        \\text{Prediction\\,:}\\;   & {}\\cancel{3}\\, y +6\n",
       "        \\end{aligned}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== sample id: 9 =====\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{aligned}\n",
       "        \\text{Ground truth\\,:}\\; & {}x + 2 y\\\\\n",
       "        \\text{Prediction\\,:}\\;   & {}x +\\cancel{3}\\, y\n",
       "        \\end{aligned}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== sample id: 11 =====\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\begin{aligned}\n",
       "        \\text{Ground truth\\,:}\\; & {}5 y\\\\\n",
       "        \\text{Prediction\\,:}\\;   & {}\\cancel{4}\\, y\n",
       "        \\end{aligned}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_texts, ref_texts = load_eval_results(\"results/eval_results.json\")\n",
    "\n",
    "success_cases = [(i, gen, ref) for i, (gen, ref) in enumerate(zip(gen_texts, ref_texts)) if gen == ref]\n",
    "failure_cases = [(i, gen, ref) for i, (gen, ref) in enumerate(zip(gen_texts, ref_texts)) if gen != ref]\n",
    "\n",
    "num_show = 5\n",
    "\n",
    "print('-------------------------')\n",
    "print(''' Success cases ''')\n",
    "print('-------------------------')\n",
    "for (i, gen, ref) in success_cases[:num_show]:\n",
    "    gen_expr = parse_poly(gen, [\"x\", \"y\"])\n",
    "    ref_expr = parse_poly(ref, [\"x\", \"y\"])\n",
    "\n",
    "    print(f\"===== sample id: {i+1} =====\")\n",
    "    display_with_diff(ref_expr, gen_expr)\n",
    "\n",
    "\n",
    "\n",
    "print('\\n-------------------------')\n",
    "print(''' Failure cases ''')\n",
    "print('-------------------------')\n",
    "for (i, gen, ref) in failure_cases[:num_show]:\n",
    "    gen_expr = parse_poly(gen, [\"x\", \"y\"])\n",
    "    ref_expr = parse_poly(ref, [\"x\", \"y\"])\n",
    "\n",
    "    print(f\"===== sample id: {i+1} =====\")\n",
    "    display_with_diff(ref_expr, gen_expr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
