{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick‑start: Hard‑coded Training Script\n",
    "\n",
    "This notebook trains a tiny BART‑style model **without any external config files**.\n",
    "All hyper‑parameters are defined inline for clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install calt-x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'.venv (Python 3.12.9)' でセルを実行するには、 ipykernel パッケージが必要です。\n",
      "\u001b[1;31m次のコマンドを実行して、'ipykernel' を Python 環境にインストールします。\n",
      "\u001b[1;31mコマンド: '/home/sato/workspace/calt/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install calt-x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x149a5480e0f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartConfig, BartForConditionalGeneration as Transformer\n",
    "from transformers import TrainingArguments\n",
    "from calt import (\n",
    "    PolynomialTrainer,\n",
    "    data_loader,\n",
    "    count_cuda_devices,\n",
    ")\n",
    "\n",
    "import torch, random, numpy as np\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset (tiny demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to any dataset you like; here we assume the toy GCD dataset from the data‑generation notebook.\n",
    "TRAIN_PATH = \"../samples/train_raw.txt\"\n",
    "TEST_PATH  = \"../samples/test_raw.txt\"\n",
    "\n",
    "dataset, tokenizer, data_collator = data_loader(\n",
    "    train_dataset_path=TRAIN_PATH,\n",
    "    test_dataset_path=TEST_PATH,\n",
    "    field=\"GF7\",\n",
    "    num_variables=2,\n",
    "    max_degree=20,\n",
    "    max_coeff=10,\n",
    "    max_length=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = data_collator([dataset[\"train\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[38,  6, 22, 28, 11, 19, 29,  9, 22, 25, 10, 26, 19,  5, 22, 22,  6, 20,\n",
       "          24,  5, 23, 20,  7, 26, 16,  9, 19, 23,  6, 22, 19, 10, 24, 15,  5, 20,\n",
       "          18, 36, 11, 18, 32, 11, 18, 30,  5, 22, 23,  9, 18, 26,  5, 22, 21, 11,\n",
       "          18, 25,  9, 18, 24,  6, 16, 24,  5, 22, 16,  9, 18, 19, 10, 20, 15,  5,\n",
       "          16, 18, 39]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1]]),\n",
       " 'decoder_input_ids': tensor([[38,  9, 16, 24,  7, 20, 15,  6, 16, 18]]),\n",
       " 'decoder_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'labels': tensor([[ 9, 16, 24,  7, 20, 15,  6, 16, 18, 39]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> C-2 E7 E13 C3 E4 E14 C1 E7 E10 C2 E11 E4 C-3 E7 E7 C-2 E5 E9 C-3 E8 E5 C-1 E11 E1 C1 E4 E8 C-2 E7 E4 C2 E9 E0 C-3 E5 E3 [SEP] C3 E3 E17 C3 E3 E15 C-3 E7 E8 C1 E3 E11 C-3 E7 E6 C3 E3 E10 C1 E3 E9 C-2 E1 E9 C-3 E7 E1 C1 E3 E4 C2 E5 E0 C-3 E1 E3 </s>\n",
      "<s> C1 E1 E9 C-1 E5 E0 C-2 E1 E3\n",
      "C1 E1 E9 C-1 E5 E0 C-2 E1 E3 </s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(sample1[\"input_ids\"][0]))\n",
    "print(tokenizer.decode(sample1[\"decoder_input_ids\"][0]))\n",
    "print(tokenizer.decode(sample1[\"labels\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = data_collator([dataset[\"test\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[38,  6, 22, 28, 11, 19, 29,  9, 22, 25, 10, 26, 19,  5, 22, 22,  6, 20,\n",
       "          24,  5, 23, 20,  7, 26, 16,  9, 19, 23,  6, 22, 19, 10, 24, 15,  5, 20,\n",
       "          18, 36, 11, 18, 32, 11, 18, 30,  5, 22, 23,  9, 18, 26,  5, 22, 21, 11,\n",
       "          18, 25,  9, 18, 24,  6, 16, 24,  5, 22, 16,  9, 18, 19, 10, 20, 15,  5,\n",
       "          16, 18, 39]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1]]),\n",
       " 'decoder_input_ids': tensor([[38,  9, 16, 24,  7, 20, 15,  6, 16, 18]]),\n",
       " 'decoder_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'labels': tensor([[ 9, 16, 24,  7, 20, 15,  6, 16, 18, 39]])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> C-2 E7 E13 C3 E4 E14 C1 E7 E10 C2 E11 E4 C-3 E7 E7 C-2 E5 E9 C-3 E8 E5 C-1 E11 E1 C1 E4 E8 C-2 E7 E4 C2 E9 E0 C-3 E5 E3 [SEP] C3 E3 E17 C3 E3 E15 C-3 E7 E8 C1 E3 E11 C-3 E7 E6 C3 E3 E10 C1 E3 E9 C-2 E1 E9 C-3 E7 E1 C1 E3 E4 C2 E5 E0 C-3 E1 E3 </s>\n",
      "<s> C1 E1 E9 C-1 E5 E0 C-2 E1 E3\n",
      "C1 E1 E9 C-1 E5 E0 C-2 E1 E3 </s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(sample2[\"input_ids\"][0]))\n",
    "print(tokenizer.decode(sample2[\"decoder_input_ids\"][0]))\n",
    "print(tokenizer.decode(sample2[\"labels\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal architecture — only overriding d_model for speed.\n",
    "model_cfg = BartConfig(\n",
    "    d_model=256,\n",
    "    vocab_size=len(tokenizer.vocab),\n",
    "    encoder_layers=6,\n",
    "    decoder_layers=6,\n",
    "    max_position_embeddings=256,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "model = Transformer(config=model_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TrainingArguments (defaults + a few essentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"results/demo\",\n",
    "    num_train_epochs=100,\n",
    "    per_device_train_batch_size=int(128),\n",
    "    per_device_eval_batch_size=int(128),\n",
    "    save_strategy=\"no\",   # skip checkpoints for the quick demo\n",
    "    seed=SEED,\n",
    "    remove_unused_columns=False,\n",
    "    label_names=[\"labels\"],\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Trainer & run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sato/workspace/calt/src/calt/trainer/trainer.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `PolynomialTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "/home/sato/workspace/calt/.venv/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:34, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = PolynomialTrainer(\n",
    "    args=args,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset[\"train\"],  # slice for speed\n",
    "    eval_dataset=dataset[\"test\"],\n",
    ")\n",
    "\n",
    "# train\n",
    "results = trainer.train()\n",
    "trainer.save_model()\n",
    "metrics = results.metrics\n",
    "\n",
    "# eval\n",
    "eval_metrics = trainer.evaluate()\n",
    "metrics.update(eval_metrics)\n",
    "acc = trainer.generate_evaluation()\n",
    "metrics[\"test_accuracy\"] = acc\n",
    "\n",
    "# save metrics\n",
    "trainer.save_metrics(\"all\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above is all you need for a first experiment.  \n",
    "Increase `num_train_epochs`, remove the slicing, and enable checkpointing/WandB when you move from a demo to full‑scale training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
