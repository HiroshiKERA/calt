{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick‑start: Hard‑coded Training Script\n",
    "\n",
    "This notebook trains a tiny BART‑style model **without any external config files**.\n",
    "All hyper‑parameters are defined inline for clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install calt-x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'.venv (Python 3.12.9)' でセルを実行するには、 ipykernel パッケージが必要です。\n",
      "\u001b[1;31m次のコマンドを実行して、'ipykernel' を Python 環境にインストールします。\n",
      "\u001b[1;31mコマンド: '/home/sato/workspace/calt/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install calt-x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sato/workspace/calt/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14bdad998990>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartConfig, BartForConditionalGeneration as Transformer\n",
    "from transformers import TrainingArguments\n",
    "from calt import (\n",
    "    PolynomialTrainer,\n",
    "    data_loader,\n",
    ")\n",
    "import torch, random, numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset (tiny demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to any dataset you like; here we assume the toy GCD dataset from the data‑generation notebook.\n",
    "# TRAIN_PATH = \"../samples/train_raw.txt\"\n",
    "# TEST_PATH = \"../samples/test_raw.txt\"\n",
    "TRAIN_PATH = \"/home/sato/workspace/calt/notebooks/dataset/partial_sum_problem/GF7_n=2/test_raw.txt\"\n",
    "TEST_PATH = \"/home/sato/workspace/calt/notebooks/dataset/partial_sum_problem/GF7_n=2/test_raw.txt\"\n",
    "dataset, tokenizer, data_collator = data_loader(\n",
    "    train_dataset_path=TRAIN_PATH,\n",
    "    test_dataset_path=TEST_PATH,\n",
    "    field=\"GF7\",\n",
    "    num_variables=2,\n",
    "    max_degree=10,\n",
    "    max_coeff=10,\n",
    "    max_length=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = data_collator([dataset[\"train\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[28,  9, 15, 16, 11, 15, 15, 26, 11, 17, 23,  9, 22, 15, 26, 14, 15, 16,\n",
       "          26,  9, 18, 15, 14, 16, 17, 11, 15, 15, 26, 10, 18, 19,  9, 17, 19, 12,\n",
       "          16, 18, 11, 15, 17, 29]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'decoder_input_ids': tensor([[28,  9, 15, 16, 11, 15, 15, 26, 11, 17, 23,  9, 22, 15,  9, 15, 16, 11,\n",
       "          15, 15, 26, 11, 17, 23,  9, 22, 15, 11, 15, 15, 26, 11, 17, 23,  9, 22,\n",
       "          15,  9, 18, 15, 14, 16, 17, 14, 15, 15, 26, 11, 17, 23,  9, 22, 15, 10,\n",
       "          18, 19,  9, 17, 19, 12, 16, 18,  9, 18, 15, 14, 16, 17, 11, 15, 17, 14,\n",
       "          15, 15]]),\n",
       " 'decoder_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1]]),\n",
       " 'labels': tensor([[ 9, 15, 16, 11, 15, 15, 26, 11, 17, 23,  9, 22, 15,  9, 15, 16, 11, 15,\n",
       "          15, 26, 11, 17, 23,  9, 22, 15, 11, 15, 15, 26, 11, 17, 23,  9, 22, 15,\n",
       "           9, 18, 15, 14, 16, 17, 14, 15, 15, 26, 11, 17, 23,  9, 22, 15, 10, 18,\n",
       "          19,  9, 17, 19, 12, 16, 18,  9, 18, 15, 14, 16, 17, 11, 15, 17, 14, 15,\n",
       "          15, 29]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> C1 E0 E1 C3 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 [SEP] C6 E0 E1 [SEP] C1 E3 E0 C6 E1 E2 C3 E0 E0 [SEP] C2 E3 E4 C1 E2 E4 C4 E1 E3 C3 E0 E2 </s>\n",
      "<s> C1 E0 E1 C3 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C1 E0 E1 C3 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C3 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C1 E3 E0 C6 E1 E2 C6 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C2 E3 E4 C1 E2 E4 C4 E1 E3 C1 E3 E0 C6 E1 E2 C3 E0 E2 C6 E0 E0\n",
      "C1 E0 E1 C3 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C1 E0 E1 C3 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C3 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C1 E3 E0 C6 E1 E2 C6 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C2 E3 E4 C1 E2 E4 C4 E1 E3 C1 E3 E0 C6 E1 E2 C3 E0 E2 C6 E0 E0 </s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(sample1[\"input_ids\"][0]))\n",
    "print(tokenizer.decode(sample1[\"decoder_input_ids\"][0]))\n",
    "print(tokenizer.decode(sample1[\"labels\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = data_collator([dataset[\"test\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[28,  9, 15, 16, 11, 15, 15, 26, 11, 17, 23,  9, 22, 15, 26, 14, 15, 16,\n",
       "          26,  9, 18, 15, 14, 16, 17, 11, 15, 15, 26, 10, 18, 19,  9, 17, 19, 12,\n",
       "          16, 18, 11, 15, 17, 29]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'decoder_input_ids': tensor([[28,  9, 15, 16, 11, 15, 15, 26, 11, 17, 23,  9, 22, 15,  9, 15, 16, 11,\n",
       "          15, 15, 26, 11, 17, 23,  9, 22, 15, 11, 15, 15, 26, 11, 17, 23,  9, 22,\n",
       "          15,  9, 18, 15, 14, 16, 17, 14, 15, 15, 26, 11, 17, 23,  9, 22, 15, 10,\n",
       "          18, 19,  9, 17, 19, 12, 16, 18,  9, 18, 15, 14, 16, 17, 11, 15, 17, 14,\n",
       "          15, 15]]),\n",
       " 'decoder_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1]]),\n",
       " 'labels': tensor([[ 9, 15, 16, 11, 15, 15, 26, 11, 17, 23,  9, 22, 15,  9, 15, 16, 11, 15,\n",
       "          15, 26, 11, 17, 23,  9, 22, 15, 11, 15, 15, 26, 11, 17, 23,  9, 22, 15,\n",
       "           9, 18, 15, 14, 16, 17, 14, 15, 15, 26, 11, 17, 23,  9, 22, 15, 10, 18,\n",
       "          19,  9, 17, 19, 12, 16, 18,  9, 18, 15, 14, 16, 17, 11, 15, 17, 14, 15,\n",
       "          15, 29]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> C1 E0 E1 C3 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 [SEP] C6 E0 E1 [SEP] C1 E3 E0 C6 E1 E2 C3 E0 E0 [SEP] C2 E3 E4 C1 E2 E4 C4 E1 E3 C3 E0 E2 </s>\n",
      "<s> C1 E0 E1 C3 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C1 E0 E1 C3 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C3 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C1 E3 E0 C6 E1 E2 C6 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C2 E3 E4 C1 E2 E4 C4 E1 E3 C1 E3 E0 C6 E1 E2 C3 E0 E2 C6 E0 E0\n",
      "C1 E0 E1 C3 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C1 E0 E1 C3 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C3 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C1 E3 E0 C6 E1 E2 C6 E0 E0 [SEP] C3 E2 E8 C1 E7 E0 C2 E3 E4 C1 E2 E4 C4 E1 E3 C1 E3 E0 C6 E1 E2 C3 E0 E2 C6 E0 E0 </s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(sample2[\"input_ids\"][0]))\n",
    "print(tokenizer.decode(sample2[\"decoder_input_ids\"][0]))\n",
    "print(tokenizer.decode(sample2[\"labels\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal architecture — only overriding d_model for speed.\n",
    "model_cfg = BartConfig(\n",
    "    d_model=256,\n",
    "    vocab_size=len(tokenizer.vocab),\n",
    "    encoder_layers=6,\n",
    "    decoder_layers=6,\n",
    "    max_position_embeddings=256,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    decoder_start_token_id=tokenizer.bos_token_id,\n",
    "    max_length=256,\n",
    ")\n",
    "model = Transformer(config=model_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TrainingArguments (defaults + a few essentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"results/demo\",\n",
    "    num_train_epochs=10,\n",
    "    logging_steps=50,\n",
    "    per_device_train_batch_size=int(32),\n",
    "    per_device_eval_batch_size=int(32),\n",
    "    save_strategy=\"no\",  # skip checkpoints for the quick demo\n",
    "    seed=SEED,\n",
    "    remove_unused_columns=False,\n",
    "    label_names=[\"labels\"],\n",
    "    report_to=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Trainer & run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msugarl\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sato/workspace/calt/notebooks/wandb/run-20250609_223444-17vgge79</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sugarl/huggingface/runs/17vgge79' target=\"_blank\">results/demo</a></strong> to <a href='https://wandb.ai/sugarl/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sugarl/huggingface' target=\"_blank\">https://wandb.ai/sugarl/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sugarl/huggingface/runs/17vgge79' target=\"_blank\">https://wandb.ai/sugarl/huggingface/runs/17vgge79</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sato/workspace/calt/.venv/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sato/workspace/calt/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3465: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 256}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = PolynomialTrainer(\n",
    "    args=args,\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset[\"train\"],  # slice for speed\n",
    "    eval_dataset=dataset[\"test\"],\n",
    ")\n",
    "\n",
    "# train\n",
    "results = trainer.train()\n",
    "trainer.save_model()\n",
    "metrics = results.metrics\n",
    "\n",
    "# eval\n",
    "eval_metrics = trainer.evaluate()\n",
    "metrics.update(eval_metrics)\n",
    "acc = trainer.generate_evaluation(max_length=128)\n",
    "metrics[\"test_accuracy\"] = acc\n",
    "\n",
    "# save metrics\n",
    "trainer.save_metrics(\"all\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_poly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m pred_tokens = \u001b[33m\"\u001b[39m\u001b[33mC1 E1 E1 C-2 E2 E1 C-3 E1 E9 C-2 E0 E7\u001b[39m\u001b[33m\"\u001b[39m   \u001b[38;5;66;03m# 係数・指数をわざと誤る\u001b[39;00m\n\u001b[32m      8\u001b[39m x, y = symbols(\u001b[33m\"\u001b[39m\u001b[33mx y\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m gold_expr = \u001b[43mparse_poly\u001b[49m(gold_tokens, [x, y])\n\u001b[32m     10\u001b[39m pred_expr = parse_poly(pred_tokens, [x, y])\n\u001b[32m     12\u001b[39m display_with_diff(gold_expr, pred_expr, [x, y])\n",
      "\u001b[31mNameError\u001b[39m: name 'parse_poly' is not defined"
     ]
    }
   ],
   "source": [
    "from sympy import symbols\n",
    "from comparison_vis import display_with_diff\n",
    "\n",
    "# --- sample tokens ---\n",
    "gold_tokens = \"C1 E1 E1 C-1 E2 E1 C-3 E1 E8 C-1 E0 E7\"\n",
    "pred_tokens = \"C1 E1 E1 C-2 E2 E1 C-3 E1 E9 C-2 E0 E7\"   # 係数・指数をわざと誤る\n",
    "\n",
    "x, y = symbols(\"x y\")\n",
    "gold_expr = parse_poly(gold_tokens, [x, y])\n",
    "pred_expr = parse_poly(pred_tokens, [x, y])\n",
    "\n",
    "display_with_diff(gold_expr, pred_expr, [x, y])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above is all you need for a first experiment.  \n",
    "Increase `num_train_epochs`, remove the slicing, and enable checkpointing/WandB when you move from a demo to full‑scale training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Union\n",
    "from sympy import symbols, Symbol, Integer\n",
    "\n",
    "\n",
    "def parse_poly(tokens: str, var_names: Sequence[Union[str, Symbol]] | None = None):\n",
    "    \"\"\"\n",
    "    Convert an internal token sequence (e.g. ``\"C1 E1 E1 C-3 E0 E7\"``)\n",
    "    into a SymPy polynomial.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens : str\n",
    "        Whitespace-separated string where a token starting with ``C`` indicates\n",
    "        a coefficient and the following ``E`` tokens indicate exponents.\n",
    "    var_names : Sequence[str | sympy.Symbol] | None, optional\n",
    "        Variable names (either strings or pre-created Symbol objects).  If\n",
    "        ``None`` (default), variables are auto-generated as x0, x1, …\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sympy.Expr\n",
    "        A SymPy expression corresponding to the polynomial.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the token sequence is malformed or the number of variables does not\n",
    "        match ``var_names``.\n",
    "    \"\"\"\n",
    "    parts = tokens.strip().split()\n",
    "    if not parts or not parts[0].startswith(\"C\"):\n",
    "        raise ValueError(\"Token sequence must start with a 'C' coefficient token.\")\n",
    "\n",
    "    # --- Infer the number of variables from the first term ------------------ #\n",
    "    try:\n",
    "        next_c_idx = parts.index(next(p for p in parts[1:] if p.startswith(\"C\")))\n",
    "        n_vars = next_c_idx - 1\n",
    "    except StopIteration:  # single-term polynomial\n",
    "        n_vars = len([p for p in parts[1:] if p.startswith(\"E\")])\n",
    "\n",
    "    # --- Prepare SymPy symbols --------------------------------------------- #\n",
    "    if var_names is None:\n",
    "        vars_ = symbols(\" \".join(f\"x{i}\" for i in range(n_vars)))\n",
    "    else:\n",
    "        if len(var_names) != n_vars:\n",
    "            raise ValueError(\n",
    "                f\"Expected {n_vars} variable name(s), got {len(var_names)}.\"\n",
    "            )\n",
    "        # If elements are strings, create Symbols; if they are already Symbols, reuse them.\n",
    "        if all(isinstance(v, str) for v in var_names):\n",
    "            vars_ = symbols(\" \".join(var_names))  # -> tuple(Symbol, …)\n",
    "        elif all(isinstance(v, Symbol) for v in var_names):\n",
    "            vars_ = tuple(var_names)\n",
    "        else:\n",
    "            raise TypeError(\"var_names must be all str or all sympy.Symbol.\")\n",
    "\n",
    "    expr = Integer(0)\n",
    "    i = 0\n",
    "    while i < len(parts):\n",
    "        # Read coefficient\n",
    "        coeff_token = parts[i]\n",
    "        if not coeff_token.startswith(\"C\"):\n",
    "            raise ValueError(f\"Expected 'C' token at position {i}, got {coeff_token}.\")\n",
    "        coeff = Integer(coeff_token[1:])\n",
    "        i += 1\n",
    "\n",
    "        # Read exponents\n",
    "        exps = []\n",
    "        for _ in range(n_vars):\n",
    "            if i >= len(parts) or not parts[i].startswith(\"E\"):\n",
    "                raise ValueError(f\"Missing 'E' token at position {i}.\")\n",
    "            exps.append(Integer(parts[i][1:]))\n",
    "            i += 1\n",
    "\n",
    "        # Build term\n",
    "        term = coeff\n",
    "        for v, e in zip(vars_, exps):\n",
    "            term *= v**e\n",
    "        expr += term\n",
    "\n",
    "    return expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-x**2*y - 3*x*y**8 + x*y - y**7\n",
      "-x**2*y - 3*x*y**8 + x*y - y**7\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, expand, init_printing\n",
    "\n",
    "init_printing(use_latex=\"mathjax\")\n",
    "\n",
    "tokens = \"C1 E1 E1 C-1 E2 E1 C-3 E1 E8 C-1 E0 E7\"\n",
    "x, y = symbols(\"x y\")\n",
    "\n",
    "# Case 1: pass SymPy symbols\n",
    "poly1 = parse_poly(tokens, [x, y])\n",
    "print(expand(poly1))\n",
    "# x*y - x**2*y - 3*x*y**8 - y**7\n",
    "\n",
    "# Case 2: pass variable names as strings\n",
    "poly2 = parse_poly(tokens, [\"x\", \"y\"])\n",
    "print(expand(poly2))\n",
    "# x*y - x**2*y - 3*x*y**8 - y**7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - x^{2} y - 3 x y^{8} + x y - y^{7}$"
      ],
      "text/plain": [
       "   2          8          7\n",
       "- x ⋅y - 3⋅x⋅y  + x⋅y - y "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Mapping\n",
    "import re\n",
    "from sympy import Expr, Symbol, latex\n",
    "from IPython.display import display, Math\n",
    "\n",
    "\n",
    "def display_poly_highlight(\n",
    "    expr: Expr,\n",
    "    highlight_syms: Mapping[Symbol, str] | None = None,\n",
    "    exp_cmd: str | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Render a SymPy expression in Colab with optional coloring/formatting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    expr : sympy.Expr\n",
    "        The polynomial (or any expression) to display.\n",
    "    highlight_syms : Mapping[Symbol, str] | None\n",
    "        Mapping from a Symbol to its LaTeX replacement string\n",
    "        (e.g. {x: r\"\\\\color{red}{x}\"}).\n",
    "    exp_cmd : str | None\n",
    "        LaTeX command (without backslash) to wrap every **numeric exponent**.\n",
    "        Examples: \"color{blue}\", \"mathbf\", \"underline\".\n",
    "        Pass ``None`` to leave exponents unchanged.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Requires MathJax (enabled by default in Google Colab).\n",
    "    - ``highlight_syms`` uses the `symbol_names` feature of SymPy's\n",
    "      ``latex()`` printer, so the expression is re-LaTeXed only once.\n",
    "    - Exponent styling is done via a regex post-processing step because\n",
    "      SymPy does not expose each exponent token separately.\n",
    "    \"\"\"\n",
    "    # 1) custom names for selected symbols ---------------------------------- #\n",
    "    sym_names = {s: rep for s, rep in (highlight_syms or {}).items()}\n",
    "\n",
    "    # 2) base LaTeX string\n",
    "    tex = latex(expr, symbol_names=sym_names)\n",
    "\n",
    "    # 3) post-process numeric exponents if requested ------------------------ #\n",
    "    if exp_cmd:\n",
    "        # Match ^{<digits>} but ignore already formatted ones\n",
    "        tex = re.sub(\n",
    "            r\"\\^\\{(\\d+)\\}\",\n",
    "            lambda m: f\"^{{\\\\{exp_cmd}{{{m.group(1)}}}}}\",\n",
    "            tex,\n",
    "        )\n",
    "\n",
    "    display(Math(tex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\color{red}{x}^{\\color{blue}\\mathbf{2}} y - 3 \\color{red}{x} y^{\\color{blue}\\mathbf{8}} + \\color{red}{x} y - y^{\\color{blue}\\mathbf{7}}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sympy import symbols, Poly\n",
    "\n",
    "# サンプル多項式\n",
    "x, y = symbols(\"x y\")\n",
    "expr = x * y - x**2 * y - 3 * x * y**8 - y**7\n",
    "\n",
    "# 変数 x を赤、指数を青太字に\n",
    "display_poly_highlight(\n",
    "    expr,\n",
    "    highlight_syms={x: r\"\\color{red}{x}\"},\n",
    "    exp_cmd=\"color{blue}\\\\mathbf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\text{Gold:}\\; - x^{2} y - 3 x y^{8} + x y - y^{7}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\text{Predicted:}\\; -\\cancel{2}\\, x^{2}\\, y +\\cancel{-3\\, x\\, y^{9}} +x\\, y -\\cancel{2}\\, y^{7}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sympy import symbols\n",
    "from comparison_vis import display_with_diff\n",
    "\n",
    "# --- sample tokens ---\n",
    "gold_tokens = \"C1 E1 E1 C-1 E2 E1 C-3 E1 E8 C-1 E0 E7\"\n",
    "pred_tokens = \"C1 E1 E1 C-2 E2 E1 C-3 E1 E9 C-2 E0 E7\"  # 係数・指数をわざと誤る\n",
    "\n",
    "x, y = symbols(\"x y\")\n",
    "gold_expr = parse_poly(gold_tokens, [x, y])\n",
    "pred_expr = parse_poly(pred_tokens, [x, y])\n",
    "\n",
    "display_with_diff(gold_expr, pred_expr, [x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sympy import symbols, sympify\n",
    "\n",
    "\n",
    "def strip_mod(expr_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove all substrings like ' mod 7', ' mod 23', … from a string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    expr_str : str\n",
    "        String representation of a SymPy polynomial such as\n",
    "        '6 mod 7*x**2*y + 4 mod 7*x*y**8 + x*y + 6 mod 7*y**7'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Cleaned string, e.g.\n",
    "        '6*x**2*y + 4*x*y**8 + x*y + 6*y**7'.\n",
    "    \"\"\"\n",
    "    # pattern: optional spaces + 'mod' + optional spaces + digits\n",
    "    pattern = r\"\\s*mod\\s*\\d+\"\n",
    "    cleaned = re.sub(pattern, \"\", expr_str)\n",
    "    # collapse multiple spaces that may remain\n",
    "    cleaned = re.sub(r\"\\s{2,}\", \" \", cleaned)\n",
    "    return cleaned.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "supported monomial orderings are 'lex', 'grlex' and 'grevlex', got 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/calt/.venv/lib/python3.12/site-packages/sympy/polys/orderings.py:230\u001b[39m, in \u001b[36mmonomial_key\u001b[39m\u001b[34m(order, gens)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     order = \u001b[43m_monomial_key\u001b[49m\u001b[43m[\u001b[49m\u001b[43morder\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[31mKeyError\u001b[39m: 'y'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# --- GF(7) 多項式を例として生成 ----------------------------------- #\u001b[39;00m\n\u001b[32m      5\u001b[39m x, y = symbols(\u001b[33m\"\u001b[39m\u001b[33mx y\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m R = \u001b[43mPolynomialRing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGF\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m f = R.from_dict({(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m): \u001b[32m6\u001b[39m, (\u001b[32m1\u001b[39m, \u001b[32m8\u001b[39m): \u001b[32m4\u001b[39m, (\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m): \u001b[32m1\u001b[39m, (\u001b[32m0\u001b[39m, \u001b[32m7\u001b[39m): \u001b[32m6\u001b[39m})\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# ① PolyElement → 文字列\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/calt/.venv/lib/python3.12/site-packages/sympy/polys/domains/polynomialring.py:25\u001b[39m, in \u001b[36mPolynomialRing.__init__\u001b[39m\u001b[34m(self, domain_or_ring, symbols, order)\u001b[39m\n\u001b[32m     23\u001b[39m     ring = domain_or_ring\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     ring = \u001b[43mPolyRing\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain_or_ring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mself\u001b[39m.ring = ring\n\u001b[32m     28\u001b[39m \u001b[38;5;28mself\u001b[39m.dtype = ring.dtype\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/calt/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:209\u001b[39m, in \u001b[36mPolyRing.__new__\u001b[39m\u001b[34m(cls, symbols, domain, order)\u001b[39m\n\u001b[32m    207\u001b[39m ngens = \u001b[38;5;28mlen\u001b[39m(symbols)\n\u001b[32m    208\u001b[39m domain = DomainOpt.preprocess(domain)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m order = \u001b[43mOrderOpt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m _hash_tuple = (\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m, symbols, ngens, domain, order)\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m domain.is_Composite \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mset\u001b[39m(symbols) & \u001b[38;5;28mset\u001b[39m(domain.symbols):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/calt/.venv/lib/python3.12/site-packages/sympy/polys/polyoptions.py:363\u001b[39m, in \u001b[36mOrder.preprocess\u001b[39m\u001b[34m(cls, order)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreprocess\u001b[39m(\u001b[38;5;28mcls\u001b[39m, order):\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msympy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpolys\u001b[49m\u001b[43m.\u001b[49m\u001b[43morderings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonomial_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/calt/.venv/lib/python3.12/site-packages/sympy/polys/orderings.py:232\u001b[39m, in \u001b[36mmonomial_key\u001b[39m\u001b[34m(order, gens)\u001b[39m\n\u001b[32m    230\u001b[39m         order = _monomial_key[order]\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msupported monomial orderings are \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlex\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mgrlex\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mgrevlex\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % order)\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(order, \u001b[33m'\u001b[39m\u001b[33m__call__\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: supported monomial orderings are 'lex', 'grlex' and 'grevlex', got 'y'"
     ]
    }
   ],
   "source": [
    "from sympy.polys.domains import GF\n",
    "from sympy.polys import PolynomialRing\n",
    "\n",
    "# --- GF(7) 多項式を例として生成 ----------------------------------- #\n",
    "x, y = symbols(\"x y\")\n",
    "R = PolynomialRing(GF(7), x, y)\n",
    "f = R.from_dict({(2, 1): 6, (1, 8): 4, (1, 1): 1, (0, 7): 6})\n",
    "\n",
    "# ① PolyElement → 文字列\n",
    "s = str(f)  # '6 mod 7*x**2*y + 4 mod 7*x*y**8 + x*y + 6 mod 7*y**7'\n",
    "\n",
    "# ② ' mod n' 部分を削除\n",
    "clean_s = strip_mod(s)  # '6*x**2*y + 4*x*y**8 + x*y + 6*y**7'\n",
    "print(clean_s)\n",
    "\n",
    "# ③ 必要なら再度 SymPy 式へ\n",
    "clean_expr = sympify(clean_s)\n",
    "print(clean_expr.expand())\n",
    "# 6*x**2*y + 4*x*y**8 + x*y + 6*y**7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
