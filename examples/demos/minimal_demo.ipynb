{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **calt Minimal Demo**\n",
    "\n",
    "This notebook demonstrates the minimal code needed to:\n",
    "1. Generate a dataset\n",
    "2. Train a model\n",
    "3. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using development calt from: /home/ara_shun/workspace/calt/src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add development calt to path (prioritize over pip-installed version)\n",
    "# This notebook is in calt/examples/demos/, so we go up to calt/ and then to src/\n",
    "# When running in Jupyter, Path.cwd() gives the notebook's directory\n",
    "calt_dev_path = Path.cwd().parent.parent / \"src\"\n",
    "sys.path.insert(0, str(calt_dev_path))\n",
    "\n",
    "print(f\"Using development calt from: {calt_dev_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Generation\n",
    "\n",
    "<!-- Generate polynomial addition problems -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=========================== Dataset generation ===========================\n",
      "\n",
      "Starting dataset generation for 2 dataset(s)\n",
      "Dataset sizes: {'train': 10000, 'test': 1000}\n",
      "\n",
      "---------------------------------- train ----------------------------------\n",
      "Dataset size: 10000 samples  (Batch size: 10000)\n",
      "\n",
      "--- Batch 1/1 ---\n",
      "Processing samples 1-10000 (size: 10000)\n",
      "Starting parallel processing...\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 4049 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 4999 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 6049 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 7199 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 8449 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done 9799 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=1)]: Done 10000 out of 10000 | elapsed:    2.3s finished\n",
      "Parallel processing completed\n",
      "Batch 1 saved to file\n",
      "Batch 1/1 completed\n",
      "\n",
      "Overall statistics saved for train dataset\n",
      "Total time: 2.29 seconds\n",
      "\n",
      "\n",
      "---------------------------------- test ----------------------------------\n",
      "Dataset size: 1000 samples  (Batch size: 10000)\n",
      "\n",
      "--- Batch 1/1 ---\n",
      "Processing samples 1-1000 (size: 1000)\n",
      "Starting parallel processing...\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "Parallel processing completed\n",
      "Batch 1 saved to file\n",
      "Batch 1/1 completed\n",
      "\n",
      "Overall statistics saved for test dataset\n",
      "Total time: 0.24 seconds\n",
      "\n",
      "\n",
      "All datasets generated successfully!\n",
      "==========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from calt.dataset import DatasetPipeline\n",
    "from calt.dataset.sympy.utils.polynomial_sampler import PolynomialSampler\n",
    "\n",
    "\n",
    "# Define instance generator: polynomial addition\n",
    "def polynomial_addition_generator(seed):\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Initialize polynomial sampler\n",
    "    sampler = PolynomialSampler(\n",
    "        symbols=\"x0, x1\",\n",
    "        field_str=\"GF(7)\",\n",
    "        max_num_terms=2,\n",
    "        max_degree=2,\n",
    "        min_degree=1,\n",
    "    )\n",
    "\n",
    "    # Generate two polynomials\n",
    "    F = sampler.sample(num_samples=2)\n",
    "\n",
    "    # Solution is the sum\n",
    "    g = sum(F)\n",
    "\n",
    "    return F, g\n",
    "\n",
    "\n",
    "# Load config from YAML file\n",
    "cfg = OmegaConf.load(\"configs/data.yaml\")\n",
    "\n",
    "# Create dataset pipeline\n",
    "pipeline = DatasetPipeline.from_config(\n",
    "    cfg.dataset,\n",
    "    instance_generator=polynomial_addition_generator,\n",
    ")\n",
    "\n",
    "# Run dataset generation\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training\n",
    "\n",
    "<!-- Load data, create model, and train -->\n",
    "<!-- The entire training pipeline can be summarized in just a few lines: -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded 10000 samples from ./data/train_raw.txt\n",
      "Loaded 1000 samples from ./data/test_raw.txt\n",
      "/home/ara_shun/anaconda3/envs/calt-env/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n",
      "/home/ara_shun/workspace/calt/src/calt/trainer/trainer.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating test dataset tokens... passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /home/ara_shun/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshun-arkw\u001b[0m (\u001b[33mchiba-u\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/home/ara_shun/anaconda3/envs/calt-env/lib/python3.12/site-packages/wandb/analytics/sentry.py:268: DeprecationWarning: Read the `app_url` setting from the appropriate Settings object.\n",
      "  app_url = wandb.util.app_url(tags[\"base_url\"])  # type: ignore[index]\n",
      "/home/ara_shun/anaconda3/envs/calt-env/lib/python3.12/site-packages/wandb/analytics/sentry.py:279: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n",
      "  self.scope.user = {\"email\": email}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ara_shun/anaconda3/envs/calt-env/lib/python3.12/site-packages/wandb/analytics/sentry.py:268: DeprecationWarning: Read the `app_url` setting from the appropriate Settings object.\n",
      "  app_url = wandb.util.app_url(tags[\"base_url\"])  # type: ignore[index]\n",
      "/home/ara_shun/anaconda3/envs/calt-env/lib/python3.12/site-packages/wandb/analytics/sentry.py:279: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n",
      "  self.scope.user = {\"email\": email}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ara_shun/workspace/calt/examples/demos/wandb/run-20260220_002939-hp2h3gdu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/chiba-u/huggingface/runs/hp2h3gdu' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/chiba-u/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/chiba-u/huggingface' target=\"_blank\">https://wandb.ai/chiba-u/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/chiba-u/huggingface/runs/hp2h3gdu' target=\"_blank\">https://wandb.ai/chiba-u/huggingface/runs/hp2h3gdu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4562, 'grad_norm': 2.586801052093506, 'learning_rate': 3.121019108280255e-05, 'epoch': 0.1597444089456869}\n",
      "{'loss': 2.7497, 'grad_norm': 2.959867238998413, 'learning_rate': 6.305732484076433e-05, 'epoch': 0.3194888178913738}\n",
      "{'loss': 1.9537, 'grad_norm': 3.6162636280059814, 'learning_rate': 9.490445859872612e-05, 'epoch': 0.4792332268370607}\n",
      "{'loss': 1.4452, 'grad_norm': 2.590085506439209, 'learning_rate': 9.701704545454547e-05, 'epoch': 0.6389776357827476}\n",
      "{'loss': 1.1572, 'grad_norm': 2.9573867321014404, 'learning_rate': 9.346590909090909e-05, 'epoch': 0.7987220447284346}\n",
      "{'loss': 0.9915, 'grad_norm': 4.354540824890137, 'learning_rate': 8.991477272727273e-05, 'epoch': 0.9584664536741214}\n",
      "{'loss': 0.8737, 'grad_norm': 4.0169525146484375, 'learning_rate': 8.636363636363637e-05, 'epoch': 1.1182108626198084}\n",
      "{'loss': 0.7918, 'grad_norm': 3.4501237869262695, 'learning_rate': 8.28125e-05, 'epoch': 1.2779552715654952}\n",
      "{'loss': 0.7427, 'grad_norm': 3.9847371578216553, 'learning_rate': 7.926136363636364e-05, 'epoch': 1.4376996805111821}\n",
      "{'loss': 0.6801, 'grad_norm': 5.632650852203369, 'learning_rate': 7.571022727272727e-05, 'epoch': 1.5974440894568689}\n",
      "{'loss': 0.648, 'grad_norm': 3.2465412616729736, 'learning_rate': 7.215909090909091e-05, 'epoch': 1.7571884984025559}\n",
      "{'loss': 0.6131, 'grad_norm': 4.567692756652832, 'learning_rate': 6.860795454545455e-05, 'epoch': 1.9169329073482428}\n",
      "{'loss': 0.5863, 'grad_norm': 5.112339496612549, 'learning_rate': 6.505681818181818e-05, 'epoch': 2.07667731629393}\n",
      "{'loss': 0.5542, 'grad_norm': 4.5925164222717285, 'learning_rate': 6.150568181818183e-05, 'epoch': 2.236421725239617}\n",
      "{'loss': 0.548, 'grad_norm': 4.399011611938477, 'learning_rate': 5.7954545454545464e-05, 'epoch': 2.3961661341853033}\n",
      "{'loss': 0.5282, 'grad_norm': 4.794643878936768, 'learning_rate': 5.44034090909091e-05, 'epoch': 2.5559105431309903}\n",
      "{'loss': 0.5164, 'grad_norm': 4.749049663543701, 'learning_rate': 5.085227272727273e-05, 'epoch': 2.7156549520766773}\n",
      "{'loss': 0.4963, 'grad_norm': 4.189481735229492, 'learning_rate': 4.7301136363636366e-05, 'epoch': 2.8753993610223643}\n",
      "{'loss': 0.4916, 'grad_norm': 5.387697219848633, 'learning_rate': 4.375e-05, 'epoch': 3.0351437699680512}\n",
      "{'loss': 0.4741, 'grad_norm': 4.286447525024414, 'learning_rate': 4.019886363636364e-05, 'epoch': 3.194888178913738}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluate_and_save_generation (step=1000, metric_key_prefix=eval)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39848592877388, 'eval_token_accuracy': 0.8766434648105181, 'eval_success_rate': 0.221, 'eval_runtime': 0.1447, 'eval_samples_per_second': 6909.925, 'eval_steps_per_second': 221.118, 'epoch': 3.194888178913738}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully saved generation results (step=1000, success_rate=0.2210)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_generation_success_rate': 0.221, 'eval_generation_step': 1000, 'epoch': 3.194888178913738}\n",
      "{'loss': 0.468, 'grad_norm': 5.521849632263184, 'learning_rate': 3.6647727272727274e-05, 'epoch': 3.3546325878594248}\n",
      "{'loss': 0.4518, 'grad_norm': 5.500566005706787, 'learning_rate': 3.3096590909090915e-05, 'epoch': 3.5143769968051117}\n",
      "{'loss': 0.4576, 'grad_norm': 3.683093547821045, 'learning_rate': 2.954545454545455e-05, 'epoch': 3.6741214057507987}\n",
      "{'loss': 0.4514, 'grad_norm': 4.174798488616943, 'learning_rate': 2.5994318181818182e-05, 'epoch': 3.8338658146964857}\n",
      "{'loss': 0.4387, 'grad_norm': 4.234916687011719, 'learning_rate': 2.244318181818182e-05, 'epoch': 3.9936102236421727}\n",
      "{'loss': 0.4402, 'grad_norm': 7.29291296005249, 'learning_rate': 1.8892045454545457e-05, 'epoch': 4.15335463258786}\n",
      "{'loss': 0.4275, 'grad_norm': 4.153010845184326, 'learning_rate': 1.534090909090909e-05, 'epoch': 4.313099041533547}\n",
      "{'loss': 0.4372, 'grad_norm': 4.2382049560546875, 'learning_rate': 1.1789772727272728e-05, 'epoch': 4.472843450479234}\n",
      "{'loss': 0.4122, 'grad_norm': 4.635823726654053, 'learning_rate': 8.238636363636363e-06, 'epoch': 4.63258785942492}\n",
      "{'loss': 0.4224, 'grad_norm': 3.573258876800537, 'learning_rate': 4.6875000000000004e-06, 'epoch': 4.792332268370607}\n",
      "{'loss': 0.425, 'grad_norm': 5.48976993560791, 'learning_rate': 1.1363636363636364e-06, 'epoch': 4.952076677316294}\n",
      "{'train_runtime': 11.6672, 'train_samples_per_second': 4285.505, 'train_steps_per_second': 134.136, 'train_loss': 0.8068843451551736, 'epoch': 5.0}\n",
      "Success rate: 27.9%\n"
     ]
    }
   ],
   "source": [
    "# Complete minimal training code\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from calt.io import IOPipeline\n",
    "from calt.models import ModelPipeline\n",
    "from calt.trainer import TrainerPipeline\n",
    "\n",
    "# Load config from YAML file\n",
    "cfg = OmegaConf.load(\"./configs/train.yaml\")\n",
    "\n",
    "# Load data\n",
    "io_pipeline = IOPipeline.from_config(cfg.data)\n",
    "result = io_pipeline.build()\n",
    "\n",
    "# Create model\n",
    "model = ModelPipeline(cfg.model, result[\"tokenizer\"]).build()\n",
    "\n",
    "# Create trainer and train\n",
    "trainer = TrainerPipeline(\n",
    "    cfg.train,\n",
    "    model=model,\n",
    "    tokenizer=result[\"tokenizer\"],\n",
    "    train_dataset=result[\"train_dataset\"],\n",
    "    eval_dataset=result[\"test_dataset\"],\n",
    "    data_collator=result[\"data_collator\"],\n",
    ").build()\n",
    "\n",
    "trainer.train()\n",
    "success_rate = trainer.evaluate_and_save_generation()\n",
    "print(f\"Success rate: {100 * success_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "calt-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
