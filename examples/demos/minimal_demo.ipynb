{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **calt Minimal Demo**\n",
    "\n",
    "This notebook demonstrates the minimal code needed to:\n",
    "1. Generate a dataset\n",
    "2. Train a model\n",
    "3. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using development calt from: /home/ara_shun/workspace/calt/src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add development calt to path (prioritize over pip-installed version)\n",
    "# This notebook is in calt/examples/demos/, so we go up to calt/ and then to src/\n",
    "# When running in Jupyter, Path.cwd() gives the notebook's directory\n",
    "calt_dev_path = Path.cwd().parent.parent / \"src\"\n",
    "sys.path.insert(0, str(calt_dev_path))\n",
    "\n",
    "print(f\"Using development calt from: {calt_dev_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Generation\n",
    "\n",
    "Generate polynomial addition problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=========================== Dataset generation ===========================\n",
      "\n",
      "Starting dataset generation for 2 dataset(s)\n",
      "Dataset sizes: {'train': 10000, 'test': 100}\n",
      "\n",
      "---------------------------------- train ----------------------------------\n",
      "Dataset size: 10000 samples  (Batch size: 100000)\n",
      "\n",
      "--- Batch 1/1 ---\n",
      "Processing samples 1-10000 (size: 10000)\n",
      "Starting parallel processing...\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 4049 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 4999 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 6049 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=1)]: Done 7199 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 8449 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done 9799 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=1)]: Done 10000 out of 10000 | elapsed:    2.2s finished\n",
      "Parallel processing completed\n",
      "Batch 1 saved to file\n",
      "Batch 1/1 completed\n",
      "\n",
      "Overall statistics saved for train dataset\n",
      "Total time: 2.24 seconds\n",
      "\n",
      "\n",
      "---------------------------------- test ----------------------------------\n",
      "Dataset size: 100 samples  (Batch size: 100000)\n",
      "\n",
      "--- Batch 1/1 ---\n",
      "Processing samples 1-100 (size: 100)\n",
      "Starting parallel processing...\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "Parallel processing completed\n",
      "Batch 1 saved to file\n",
      "Batch 1/1 completed\n",
      "\n",
      "Overall statistics saved for test dataset\n",
      "Total time: 0.02 seconds\n",
      "\n",
      "\n",
      "All datasets generated successfully!\n",
      "==========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generation completed!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from calt.dataset.sympy.dataset_generator import DatasetGenerator\n",
    "from calt.dataset.sympy.utils.polynomial_sampler import PolynomialSampler\n",
    "from calt.dataset.utils.dataset_writer import DatasetWriter\n",
    "\n",
    "\n",
    "# Define instance generator: polynomial addition\n",
    "def polynomial_addition_generator(seed):\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Initialize polynomial sampler\n",
    "    sampler = PolynomialSampler(\n",
    "        symbols=\"x0, x1\",\n",
    "        field_str=\"GF(7)\",\n",
    "        max_num_terms=2,\n",
    "        max_degree=2,\n",
    "        min_degree=1,\n",
    "    )\n",
    "\n",
    "    # Generate two polynomials\n",
    "    F = sampler.sample(num_samples=2)\n",
    "\n",
    "    # Solution is the sum\n",
    "    g = sum(F)\n",
    "\n",
    "    return F, g\n",
    "\n",
    "\n",
    "# Initialize dataset generator\n",
    "dataset_generator = DatasetGenerator(\n",
    "    n_jobs=1,  # Use 1 for demo (SymPy backend)\n",
    "    root_seed=100,\n",
    ")\n",
    "\n",
    "# Initialize dataset writer\n",
    "dataset_writer = DatasetWriter(\n",
    "    save_dir=\"./data\",\n",
    "    save_text=True,\n",
    "    save_json=False,\n",
    ")\n",
    "\n",
    "# Generate datasets\n",
    "dataset_generator.run(\n",
    "    dataset_sizes={\"train\": 10000, \"test\": 100},\n",
    "    instance_generator=polynomial_addition_generator,\n",
    "    dataset_writer=dataset_writer,\n",
    ")\n",
    "\n",
    "print(\"Dataset generation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training\n",
    "\n",
    "Load data, create model, and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "from calt.io import IOPipeline\n",
    "from calt.models import ModelPipeline\n",
    "from calt.trainer import TrainerPipeline\n",
    "\n",
    "# Load config from YAML file\n",
    "cfg = OmegaConf.load(\"./configs/config.yaml\")\n",
    "\n",
    "print(\"Config loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded 10000 samples from ./data/train_raw.txt\n",
      "Loaded 100 samples from ./data/test_raw.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating test dataset tokens... passed!\n",
      "Loaded 10000 training samples and 100 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "io_pipeline = IOPipeline.from_config(cfg.data)\n",
    "# io_pipeline.dataset_load_preprocessor = dataset_load_preprocessor\n",
    "result = io_pipeline.build()\n",
    "\n",
    "print(\n",
    "    f\"Loaded {len(result['train_dataset'])} training samples and {len(result['test_dataset'])} test samples\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Transformer (1,002,496 parameters)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ara_shun/anaconda3/envs/calt-env/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model_pipeline = ModelPipeline(cfg.model, result[\"tokenizer\"])\n",
    "model = model_pipeline.build()\n",
    "\n",
    "print(\n",
    "    f\"Model: {type(model).__name__} ({sum(p.numel() for p in model.parameters()):,} parameters)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ara_shun/workspace/calt/src/calt/trainer/trainer.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer ready\n"
     ]
    }
   ],
   "source": [
    "# Create trainer\n",
    "trainer_pipeline = TrainerPipeline(\n",
    "    cfg.train,\n",
    "    model=model,\n",
    "    tokenizer=result[\"tokenizer\"],\n",
    "    train_dataset=result[\"train_dataset\"],\n",
    "    eval_dataset=result[\"test_dataset\"],\n",
    "    data_collator=result[\"data_collator\"],\n",
    ")\n",
    "trainer = trainer_pipeline.build()\n",
    "\n",
    "print(\"Trainer ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /home/ara_shun/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshun-arkw\u001b[0m (\u001b[33mchiba-u\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/home/ara_shun/anaconda3/envs/calt-env/lib/python3.12/site-packages/wandb/analytics/sentry.py:268: DeprecationWarning: Read the `app_url` setting from the appropriate Settings object.\n",
      "  app_url = wandb.util.app_url(tags[\"base_url\"])  # type: ignore[index]\n",
      "/home/ara_shun/anaconda3/envs/calt-env/lib/python3.12/site-packages/wandb/analytics/sentry.py:279: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n",
      "  self.scope.user = {\"email\": email}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ara_shun/anaconda3/envs/calt-env/lib/python3.12/site-packages/wandb/analytics/sentry.py:268: DeprecationWarning: Read the `app_url` setting from the appropriate Settings object.\n",
      "  app_url = wandb.util.app_url(tags[\"base_url\"])  # type: ignore[index]\n",
      "/home/ara_shun/anaconda3/envs/calt-env/lib/python3.12/site-packages/wandb/analytics/sentry.py:279: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n",
      "  self.scope.user = {\"email\": email}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ara_shun/workspace/calt/examples/demos/wandb/run-20260219_123244-hm5rgxr4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/chiba-u/huggingface/runs/hm5rgxr4' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/chiba-u/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/chiba-u/huggingface' target=\"_blank\">https://wandb.ai/chiba-u/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/chiba-u/huggingface/runs/hm5rgxr4' target=\"_blank\">https://wandb.ai/chiba-u/huggingface/runs/hm5rgxr4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3729, 'grad_norm': 2.5898165702819824, 'learning_rate': 3.121019108280255e-05, 'epoch': 0.1597444089456869}\n",
      "{'loss': 2.717, 'grad_norm': 2.7342028617858887, 'learning_rate': 6.305732484076433e-05, 'epoch': 0.3194888178913738}\n",
      "{'loss': 1.9186, 'grad_norm': 2.3831541538238525, 'learning_rate': 9.490445859872612e-05, 'epoch': 0.4792332268370607}\n",
      "{'loss': 1.435, 'grad_norm': 3.7517452239990234, 'learning_rate': 9.701704545454547e-05, 'epoch': 0.6389776357827476}\n",
      "{'loss': 1.1541, 'grad_norm': 4.151821613311768, 'learning_rate': 9.346590909090909e-05, 'epoch': 0.7987220447284346}\n",
      "{'loss': 0.9795, 'grad_norm': 3.8127329349517822, 'learning_rate': 8.991477272727273e-05, 'epoch': 0.9584664536741214}\n",
      "{'loss': 0.8628, 'grad_norm': 5.033078670501709, 'learning_rate': 8.636363636363637e-05, 'epoch': 1.1182108626198084}\n",
      "{'loss': 0.779, 'grad_norm': 3.3890419006347656, 'learning_rate': 8.28125e-05, 'epoch': 1.2779552715654952}\n",
      "{'loss': 0.7093, 'grad_norm': 5.244777679443359, 'learning_rate': 7.926136363636364e-05, 'epoch': 1.4376996805111821}\n",
      "{'loss': 0.6695, 'grad_norm': 3.586505174636841, 'learning_rate': 7.571022727272727e-05, 'epoch': 1.5974440894568689}\n",
      "{'loss': 0.6304, 'grad_norm': 5.256741046905518, 'learning_rate': 7.215909090909091e-05, 'epoch': 1.7571884984025559}\n",
      "{'loss': 0.6076, 'grad_norm': 5.528529644012451, 'learning_rate': 6.860795454545455e-05, 'epoch': 1.9169329073482428}\n",
      "{'loss': 0.5778, 'grad_norm': 3.6498770713806152, 'learning_rate': 6.505681818181818e-05, 'epoch': 2.07667731629393}\n",
      "{'loss': 0.5432, 'grad_norm': 3.722006320953369, 'learning_rate': 6.150568181818183e-05, 'epoch': 2.236421725239617}\n",
      "{'loss': 0.5415, 'grad_norm': 4.2978363037109375, 'learning_rate': 5.7954545454545464e-05, 'epoch': 2.3961661341853033}\n",
      "{'loss': 0.5206, 'grad_norm': 3.638122797012329, 'learning_rate': 5.44034090909091e-05, 'epoch': 2.5559105431309903}\n",
      "{'loss': 0.5034, 'grad_norm': 4.538198471069336, 'learning_rate': 5.085227272727273e-05, 'epoch': 2.7156549520766773}\n",
      "{'loss': 0.481, 'grad_norm': 4.571220874786377, 'learning_rate': 4.7301136363636366e-05, 'epoch': 2.8753993610223643}\n",
      "{'loss': 0.4781, 'grad_norm': 4.532893657684326, 'learning_rate': 4.375e-05, 'epoch': 3.0351437699680512}\n",
      "{'loss': 0.4585, 'grad_norm': 5.727597713470459, 'learning_rate': 4.019886363636364e-05, 'epoch': 3.194888178913738}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluate_and_save_generation (step=1000, metric_key_prefix=eval)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40444302558898926, 'eval_token_accuracy': 0.8731060606060606, 'eval_success_rate': 0.23, 'eval_runtime': 0.067, 'eval_samples_per_second': 1493.033, 'eval_steps_per_second': 59.721, 'epoch': 3.194888178913738}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully saved generation results (step=1000, success_rate=0.2300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_generation_success_rate': 0.23, 'eval_generation_step': 1000, 'epoch': 3.194888178913738}\n",
      "{'loss': 0.4565, 'grad_norm': 6.167156219482422, 'learning_rate': 3.6647727272727274e-05, 'epoch': 3.3546325878594248}\n",
      "{'loss': 0.4488, 'grad_norm': 5.304116725921631, 'learning_rate': 3.3096590909090915e-05, 'epoch': 3.5143769968051117}\n",
      "{'loss': 0.4554, 'grad_norm': 4.9376983642578125, 'learning_rate': 2.954545454545455e-05, 'epoch': 3.6741214057507987}\n",
      "{'loss': 0.454, 'grad_norm': 5.564621448516846, 'learning_rate': 2.5994318181818182e-05, 'epoch': 3.8338658146964857}\n",
      "{'loss': 0.4406, 'grad_norm': 3.62054443359375, 'learning_rate': 2.244318181818182e-05, 'epoch': 3.9936102236421727}\n",
      "{'loss': 0.4295, 'grad_norm': 4.212924957275391, 'learning_rate': 1.8892045454545457e-05, 'epoch': 4.15335463258786}\n",
      "{'loss': 0.4435, 'grad_norm': 6.1024580001831055, 'learning_rate': 1.534090909090909e-05, 'epoch': 4.313099041533547}\n",
      "{'loss': 0.4324, 'grad_norm': 4.131100177764893, 'learning_rate': 1.1789772727272728e-05, 'epoch': 4.472843450479234}\n",
      "{'loss': 0.4154, 'grad_norm': 4.814300537109375, 'learning_rate': 8.238636363636363e-06, 'epoch': 4.63258785942492}\n",
      "{'loss': 0.4076, 'grad_norm': 5.031957626342773, 'learning_rate': 4.6875000000000004e-06, 'epoch': 4.792332268370607}\n",
      "{'loss': 0.4077, 'grad_norm': 4.097579479217529, 'learning_rate': 1.1363636363636364e-06, 'epoch': 4.952076677316294}\n",
      "{'train_runtime': 11.1094, 'train_samples_per_second': 4500.709, 'train_steps_per_second': 140.872, 'train_loss': 0.7940711396189924, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluate_and_save_generation (step=1565, metric_key_prefix=eval)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35647696256637573, 'eval_token_accuracy': 0.8816287878787878, 'eval_success_rate': 0.25, 'eval_runtime': 0.0619, 'eval_samples_per_second': 1616.676, 'eval_steps_per_second': 64.667, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully saved generation results (step=1565, success_rate=0.2500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_generation_success_rate': 0.25, 'eval_generation_step': 1565, 'epoch': 5.0}\n",
      "Success rate: 25.0%\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "trainer.train()\n",
    "eval_metrics = trainer.evaluate()\n",
    "success_rate = trainer.evaluate_and_save_generation()\n",
    "\n",
    "print(f\"Success rate: {100 * success_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary\n",
    "\n",
    "The entire training pipeline can be summarized in just a few lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded 10000 samples from ./data/train_raw.txt\n",
      "Loaded 100 samples from ./data/test_raw.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating test dataset tokens... passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ara_shun/anaconda3/envs/calt-env/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n",
      "/home/ara_shun/workspace/calt/src/calt/trainer/trainer.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4046, 'grad_norm': 2.5851714611053467, 'learning_rate': 3.121019108280255e-05, 'epoch': 0.1597444089456869}\n",
      "{'loss': 2.7262, 'grad_norm': 2.558344841003418, 'learning_rate': 6.305732484076433e-05, 'epoch': 0.3194888178913738}\n",
      "{'loss': 1.9646, 'grad_norm': 4.806286811828613, 'learning_rate': 9.490445859872612e-05, 'epoch': 0.4792332268370607}\n",
      "{'loss': 1.4958, 'grad_norm': 3.0744497776031494, 'learning_rate': 9.701704545454547e-05, 'epoch': 0.6389776357827476}\n",
      "{'loss': 1.196, 'grad_norm': 2.605043649673462, 'learning_rate': 9.346590909090909e-05, 'epoch': 0.7987220447284346}\n",
      "{'loss': 0.9969, 'grad_norm': 3.7370448112487793, 'learning_rate': 8.991477272727273e-05, 'epoch': 0.9584664536741214}\n",
      "{'loss': 0.8719, 'grad_norm': 4.18489408493042, 'learning_rate': 8.636363636363637e-05, 'epoch': 1.1182108626198084}\n",
      "{'loss': 0.7842, 'grad_norm': 5.51294469833374, 'learning_rate': 8.28125e-05, 'epoch': 1.2779552715654952}\n",
      "{'loss': 0.721, 'grad_norm': 6.80967903137207, 'learning_rate': 7.926136363636364e-05, 'epoch': 1.4376996805111821}\n",
      "{'loss': 0.6795, 'grad_norm': 3.8502190113067627, 'learning_rate': 7.571022727272727e-05, 'epoch': 1.5974440894568689}\n",
      "{'loss': 0.6429, 'grad_norm': 5.917803764343262, 'learning_rate': 7.215909090909091e-05, 'epoch': 1.7571884984025559}\n",
      "{'loss': 0.6184, 'grad_norm': 4.783059597015381, 'learning_rate': 6.860795454545455e-05, 'epoch': 1.9169329073482428}\n",
      "{'loss': 0.5848, 'grad_norm': 3.9235050678253174, 'learning_rate': 6.505681818181818e-05, 'epoch': 2.07667731629393}\n",
      "{'loss': 0.5573, 'grad_norm': 5.432829856872559, 'learning_rate': 6.150568181818183e-05, 'epoch': 2.236421725239617}\n",
      "{'loss': 0.5486, 'grad_norm': 4.3718647956848145, 'learning_rate': 5.7954545454545464e-05, 'epoch': 2.3961661341853033}\n",
      "{'loss': 0.5223, 'grad_norm': 3.8544914722442627, 'learning_rate': 5.44034090909091e-05, 'epoch': 2.5559105431309903}\n",
      "{'loss': 0.5127, 'grad_norm': 4.459426403045654, 'learning_rate': 5.085227272727273e-05, 'epoch': 2.7156549520766773}\n",
      "{'loss': 0.4912, 'grad_norm': 5.231328964233398, 'learning_rate': 4.7301136363636366e-05, 'epoch': 2.8753993610223643}\n",
      "{'loss': 0.4886, 'grad_norm': 4.091350555419922, 'learning_rate': 4.375e-05, 'epoch': 3.0351437699680512}\n",
      "{'loss': 0.4663, 'grad_norm': 4.642876625061035, 'learning_rate': 4.019886363636364e-05, 'epoch': 3.194888178913738}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluate_and_save_generation (step=1000, metric_key_prefix=eval)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4075268507003784, 'eval_token_accuracy': 0.8664772727272727, 'eval_success_rate': 0.19, 'eval_runtime': 0.0632, 'eval_samples_per_second': 1582.434, 'eval_steps_per_second': 63.297, 'epoch': 3.194888178913738}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully saved generation results (step=1000, success_rate=0.1900)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_generation_success_rate': 0.19, 'eval_generation_step': 1000, 'epoch': 3.194888178913738}\n",
      "{'loss': 0.4641, 'grad_norm': 5.6160149574279785, 'learning_rate': 3.6647727272727274e-05, 'epoch': 3.3546325878594248}\n",
      "{'loss': 0.4573, 'grad_norm': 3.478977918624878, 'learning_rate': 3.3096590909090915e-05, 'epoch': 3.5143769968051117}\n",
      "{'loss': 0.4641, 'grad_norm': 4.71636962890625, 'learning_rate': 2.954545454545455e-05, 'epoch': 3.6741214057507987}\n",
      "{'loss': 0.4609, 'grad_norm': 4.846352577209473, 'learning_rate': 2.5994318181818182e-05, 'epoch': 3.8338658146964857}\n",
      "{'loss': 0.4457, 'grad_norm': 3.2434637546539307, 'learning_rate': 2.244318181818182e-05, 'epoch': 3.9936102236421727}\n",
      "{'loss': 0.4421, 'grad_norm': 3.988615036010742, 'learning_rate': 1.8892045454545457e-05, 'epoch': 4.15335463258786}\n",
      "{'loss': 0.4474, 'grad_norm': 4.46818208694458, 'learning_rate': 1.534090909090909e-05, 'epoch': 4.313099041533547}\n",
      "{'loss': 0.4432, 'grad_norm': 4.820217132568359, 'learning_rate': 1.1789772727272728e-05, 'epoch': 4.472843450479234}\n",
      "{'loss': 0.4243, 'grad_norm': 5.072983264923096, 'learning_rate': 8.238636363636363e-06, 'epoch': 4.63258785942492}\n",
      "{'loss': 0.4133, 'grad_norm': 3.8769869804382324, 'learning_rate': 4.6875000000000004e-06, 'epoch': 4.792332268370607}\n",
      "{'loss': 0.4153, 'grad_norm': 3.9424667358398438, 'learning_rate': 1.1363636363636364e-06, 'epoch': 4.952076677316294}\n",
      "{'train_runtime': 9.5473, 'train_samples_per_second': 5237.097, 'train_steps_per_second': 163.921, 'train_loss': 0.8076216868318308, 'epoch': 5.0}\n",
      "Success rate: 25.0%\n"
     ]
    }
   ],
   "source": [
    "# Complete minimal training code\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from calt.io import IOPipeline\n",
    "from calt.models import ModelPipeline\n",
    "from calt.trainer import TrainerPipeline\n",
    "\n",
    "# Load config from YAML file\n",
    "cfg = OmegaConf.load(\"./configs/config.yaml\")\n",
    "\n",
    "# Load data\n",
    "io_pipeline = IOPipeline.from_config(cfg.data)\n",
    "result = io_pipeline.build()\n",
    "\n",
    "# Create model\n",
    "model = ModelPipeline(cfg.model, result[\"tokenizer\"]).build()\n",
    "\n",
    "# Create trainer and train\n",
    "trainer = TrainerPipeline(\n",
    "    cfg.train,\n",
    "    model=model,\n",
    "    tokenizer=result[\"tokenizer\"],\n",
    "    train_dataset=result[\"train_dataset\"],\n",
    "    eval_dataset=result[\"test_dataset\"],\n",
    "    data_collator=result[\"data_collator\"],\n",
    ").build()\n",
    "\n",
    "trainer.train()\n",
    "success_rate = trainer.evaluate_and_save_generation()\n",
    "print(f\"Success rate: {100 * success_rate:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "calt-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
